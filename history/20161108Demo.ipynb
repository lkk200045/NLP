{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用Jieba 切詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大\n",
      "巨蛋\n",
      "案對\n",
      "市府\n",
      "同仁\n",
      "下\n",
      "封口令\n",
      "？\n",
      "　\n",
      "柯\n",
      "P\n",
      "否認\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "\n",
    "seg_list = jieba.cut(\"大巨蛋案對市府同仁下封口令？　柯P否認\")\n",
    "for word in seg_list:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a@b@c'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a= ['a', 'b', 'c']\n",
    "'@'.join(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'大/巨蛋/案對/市府/同仁/下/封口令/？/\\u3000/柯/P/否認'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jieba\n",
    "seg_list = jieba.cut(\"大巨蛋案對市府同仁下封口令？　柯P否認\")\n",
    "'/'.join(seg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'大/巨蛋/案/對/市府/同仁/下/封口/封口令/口令////柯/P/否/認'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jieba\n",
    "seg_list = jieba.cut(\"大巨蛋案對市府同仁下封口令？　柯P否認\", cut_all=True)\n",
    "'/'.join(seg_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jieba.load_userdict('userdict.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'大巨蛋/案對/市府/同仁/下/封口令/？/\\u3000/柯P/否認'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jieba\n",
    "seg_list = jieba.cut(\"大巨蛋案對市府同仁下封口令？　柯P否認\")\n",
    "'/'.join(seg_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用Posseg 切詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大巨蛋 n\n",
      "案 ng\n",
      "對 p\n",
      "市府 n\n",
      "同仁 nr\n",
      "下 f\n",
      "封口令 n\n",
      "？ x\n",
      "　 x\n",
      "柯P n\n",
      "否認 v\n"
     ]
    }
   ],
   "source": [
    "import jieba.posseg as pseg\n",
    "words = pseg.cut(\"大巨蛋案對市府同仁下封口令？　柯P否認\")\n",
    "for w in words:\n",
    "    print(w.word, w.flag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 做Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大巨蛋 0 3\n",
      "案對 3 5\n",
      "市府 5 7\n",
      "同仁 7 9\n",
      "下 9 10\n",
      "封口令 10 13\n",
      "？ 13 14\n",
      "　 14 15\n",
      "柯P 15 17\n",
      "否認 17 19\n"
     ]
    }
   ],
   "source": [
    "sentence = \"大巨蛋案對市府同仁下封口令？　柯P否認\"\n",
    "\n",
    "words = jieba.tokenize(sentence)\n",
    "\n",
    "for tw in words:\n",
    "    print(tw[0], tw[1], tw[2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 抓出句子中的關鍵詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "封口令\n",
      "同仁\n"
     ]
    }
   ],
   "source": [
    "import jieba.analyse\n",
    "tags = jieba.analyse.extract_tags(sentence, 1)\n",
    "print(\",\".join(tags))\n",
    "\n",
    "tags = jieba.analyse.extract_tags(sentence, 1, allowPOS = ['nr'])\n",
    "print(\",\".join(tags))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "那我\n",
      "我們\n",
      "們酸\n",
      "酸民\n",
      "民婉\n",
      "婉君\n",
      "君也\n",
      "也可\n",
      "可以\n",
      "以報\n",
      "報名\n",
      "名嗎\n"
     ]
    }
   ],
   "source": [
    "#使用n = 2\n",
    "sentence='那我們酸民婉君也可以報名嗎'\n",
    "\n",
    "for i in range(0, len(sentence) - 2 + 1):\n",
    "    print(sentence[i:i+2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "那我們\n",
      "我們酸\n",
      "們酸民\n",
      "酸民婉\n",
      "民婉君\n",
      "婉君也\n",
      "君也可\n",
      "也可以\n",
      "可以報\n",
      "以報名\n",
      "報名嗎\n"
     ]
    }
   ],
   "source": [
    "#使用n = 3\n",
    "for i in range(0, len(sentence) -3 + 1):\n",
    "    print(sentence[i:i+3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "那我們酸\n",
      "我們酸民\n",
      "們酸民婉\n",
      "酸民婉君\n",
      "民婉君也\n",
      "婉君也可\n",
      "君也可以\n",
      "也可以報\n",
      "可以報名\n",
      "以報名嗎\n"
     ]
    }
   ],
   "source": [
    "#使用n = 4\n",
    "for i in range(0, len(sentence) -4 + 1):\n",
    "    print(sentence[i:i+4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 4), (2, 4)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "a= [1,2,3,1,2,2,1,3,1,2]\n",
    "c = Counter(a)\n",
    "c.most_common(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立ngram 函式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ngram(sentence, n = 2):\n",
    "    word_list  = [] \n",
    "    for i in range(0, len(sentence) - n + 1):\n",
    "        word_list.append(sentence[i:i+n])\n",
    "    return Counter(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('脫歐', 2), ('資產', 2), ('險資', 2)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = '但今日亞洲盤亞股、日圓、金價走勢，卻反映投資人還是不敢肯定希拉蕊必定勝選，畢竟5個月前英脫歐公投前夕，也是風險資產走揚，但投票當天卻因脫歐陣營意外強大，導致股市、新興市場和商品瞬間急轉直下、避險資產急漲'\n",
    "result = ngram(sentence, 2)\n",
    "result.most_common(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用正規表達法切句"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['但今日亞洲盤亞股',\n",
       " '日圓',\n",
       " '金價走勢',\n",
       " '卻反映投資人還是不敢肯定希拉蕊必定勝選',\n",
       " '畢竟5個月前英脫歐公投前夕',\n",
       " '也是風險資產走揚',\n",
       " '但投票當天卻因脫歐陣營意外強大',\n",
       " '導致股市',\n",
       " '新興市場和商品瞬間急轉直下',\n",
       " '避險資產急漲']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = '但今日亞洲盤亞股、日圓、金價走勢，卻反映投資人還是不敢肯定希拉蕊必定勝選，畢竟5個月前英脫歐公投前夕，也是風險資產走揚，但投票當天卻因脫歐陣營意外強大，導致股市、新興市場和商品瞬間急轉直下、避險資產急漲'\n",
    "import re\n",
    "re.split('、|，', sentence )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ngram(sentence, n = 2):\n",
    "    word_list  = [] \n",
    "    sentence_split = re.split('、|，|。', sentence)\n",
    "    for s in sentence_split:\n",
    "        for i in range(0, len(s) - n + 1):\n",
    "            word_list.append(s[i:i+n])\n",
    "    return Counter(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'卻反映投資人還是不敢肯定必定勝選'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = '卻反映投資人還是不敢肯定希拉蕊必定勝選'\n",
    "''.join(s.split('希拉蕊'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def removeKey(text, keyword):\n",
    "    textAry= text\n",
    "    for key in keyword:\n",
    "        textAry = ''.join(textAry.split(key))\n",
    "    return textAry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence = '''\n",
    "在山上遇到車子出現問題，真的是欲哭無淚，但這個幸運的車主遇到了超暖師生，讓他順利脫困。\n",
    "車主在臉書《爆料公社》發文表示，本月7日在新竹司馬庫斯時，右前輪突然破了沒氣，當他正急得像熱鍋上的螞蟻時，正好巧遇南港高工汽修科的師生，「師生得知後立即捲起袖子，用自己的補胎工具，熟練的將輪胎缷下進行補胎工作，對於南港高工的熱忱及慷慨解危，感到非常感激。」\n",
    "車主表示，因為港工汽修科師生的幫忙，他才能順利回到溫暖的家，但對於耽誤師生和司機回鄉的時間感到很抱歉。\n",
    "網友看了大讚「老師學生都很棒~感謝你們讓台灣感到很溫暖」、「神救援」、「你遇到最美麗風景，他們學到最棒的經驗」、「巧遇汽修科的同學 這是要多幸運的幸運」、「剛好現場教學，學以致用。」（即時新聞中心／綜合報導）\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['汽修科', '感到', '遇到', '幸運', '車主', '師生']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords = []\n",
    "# ngram 從 4 到 2\n",
    "for n in range(4,1,-1):\n",
    "    # 移除關鍵詞\n",
    "    new_sentence   = removeKey(sentence, keywords)\n",
    "    # 切ngram\n",
    "    sentence_token = ngram(new_sentence, n)\n",
    "    for token, cnt in sentence_token.items():\n",
    "        # 將超過閥值的資料加入keywords 字典中\n",
    "        if cnt >= 3:\n",
    "            keywords.append(token)\n",
    "keywords\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 統計字詞出現頻率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jieba.load_userdict('userdict.txt')\n",
    "s = '''美國民主黨總統候選人希拉蕊‧柯林頓(Hillary Clinton)陣營1名助理表示，約4萬名群眾7日湧入費城的美國獨立紀念館(Independence Mall)，參加希拉蕊的造勢活動，同時希拉蕊的夫婿柯林頓(Bill Clinton)、歐巴馬總統與妻子蜜雪兒也都出席這場造勢活動。\n",
    "搖滾歌手布魯斯史普林斯汀(Bruce Springsteen)與邦喬飛(Jon Bon Jovi)都在費城這場活動上表演。這是希拉蕊選前最後一天的倒數第二場群眾造勢活動。\n",
    "競選助理向隨行記者表示，這次的參與人數創下了希拉蕊陣營的新紀錄，先前的紀錄是在俄亥俄州的1場造勢活動，吸引了1萬8,500人參加'''\n",
    "word_list = []\n",
    "for word in jieba.cut(s):\n",
    "    word_list.append(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "活動 5\n",
      "希拉蕊 5\n",
      "造勢 3\n",
      "美國 2\n",
      "Clinton 2\n",
      "陣營 2\n",
      "助理 2\n",
      "柯林頓 2\n",
      "參加 2\n",
      "這場 2\n",
      "表示 2\n",
      "費城 2\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "c = Counter(word_list)\n",
    "\n",
    "for word, cnt in c.most_common(100):\n",
    "    if len(word)>=2 and cnt >= 2:\n",
    "        print(word, cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分析多篇文章的詞頻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "news = pandas.read_excel('news.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_list = []\n",
    "for article in news.content:\n",
    "    for word in jieba.cut(article):\n",
    "        word_list.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "報導 243\n",
      "表示 222\n",
      "台北 147\n",
      "10 143\n",
      "時間 113\n",
      "警方 108\n",
      "希拉蕊 106\n",
      "總統 105\n",
      "調查 103\n",
      "中心 103\n",
      "目前 99\n",
      "台灣 94\n",
      "今天 92\n",
      "網友 86\n",
      "可以 86\n",
      "今年 84\n",
      "自己 84\n",
      "更新 82\n",
      "政府 82\n",
      "食品 80\n",
      "可能 79\n",
      "發現 79\n",
      "因為 79\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "c = Counter(word_list)\n",
    "for word, cnt in c.most_common(100):\n",
    "    if len(word)>=2 and cnt >= 2:\n",
    "        print(word, cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 計算 TF-IDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "a, abb, abc = [\"a\"], [\"a\", \"b\", \"b\"], [\"a\", \"b\", \"c\"]\n",
    "D = [a, abb, abc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(tfidf(\"a\", a, D))\n",
    "import scipy as sp\n",
    "tf  = 1 / 1\n",
    "idf = sp.log(3 / 3 )\n",
    "\n",
    "print(tf, idf)\n",
    "print(tf * idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.270310072072\n"
     ]
    }
   ],
   "source": [
    "#print(tfidf(\"b\", abb, D))\n",
    "tf = 2 / 3\n",
    "idf = sp.log(3 / 2)\n",
    "print(tf*idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(tfidf(\"a\", abc, D))\n",
    "0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.135155036036\n"
     ]
    }
   ],
   "source": [
    "#print(tfidf(\"b\", abc, D))\n",
    "tf = 1 / 3\n",
    "idf = sp.log(3 / 2)\n",
    "print(tf*idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.366204096223\n"
     ]
    }
   ],
   "source": [
    "#print(tfidf(\"c\", abc, D))\n",
    "tf = 1 / 3\n",
    "idf = sp.log(3 / 1)\n",
    "print(tf*idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.270310072072\n",
      "0.0\n",
      "0.135155036036\n",
      "0.366204096223\n"
     ]
    }
   ],
   "source": [
    "import scipy as sp\n",
    "def tfidf(t, d, D):\n",
    "    tf = float(d.count(t)) / sum(d.count(w) for w in set(d))\n",
    "    idf = sp.log(float(len(D)) / (len([doc for doc in D if t in doc])))\n",
    "    return tf * idf\n",
    "print(tfidf(\"a\", a, D))\n",
    "print(tfidf(\"b\", abb, D))\n",
    "print(tfidf(\"a\", abc, D))\n",
    "print(tfidf(\"b\", abc, D))\n",
    "print(tfidf(\"c\", abc, D))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 計算詞頻矩陣"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "jieba.load_userdict('userdict.txt')\n",
    "ary = ['【更新】柯P：洪智坤洩漏公文案還沒看到公文　今處理',\n",
    "       '留洪智坤 柯：殘障求職不易',\n",
    "       '人事處議處洪智坤　柯P：不清楚議處結果']\n",
    "\n",
    "corpus = []\n",
    "for title in ary:\n",
    "    corpus.append(' '.join(jieba.cut(title)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['【 更新 】 柯P ： 洪智坤 洩漏 公文 案還 沒 看到 公文 \\u3000 今處理',\n",
       " '留 洪智坤   柯 ： 殘障 求職 不易',\n",
       " '人事處 議處 洪智坤 \\u3000 柯P ： 不 清楚 議處 結果']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用CountVectorizer 計算詞頻矩陣"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "不易 人事處 今處理 公文 更新 柯p 案還 殘障 求職 洩漏 洪智坤 清楚 看到 結果 議處\n",
      "[[0 0 1 2 1 1 1 0 0 1 1 0 1 0 0]\n",
      " [1 0 0 0 0 0 0 1 1 0 1 0 0 0 0]\n",
      " [0 1 0 0 0 1 0 0 0 0 1 1 0 1 2]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer() \n",
    "X = vectorizer.fit_transform(corpus)\n",
    "\n",
    "word = vectorizer.get_feature_names() \n",
    "#for w in word:\n",
    "#    print(w,)\n",
    "print(' '.join(word))\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用TFIDF Transformer 計算 TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.          0.31738473  0.63476946  0.31738473  0.24137927\n",
      "   0.31738473  0.          0.          0.31738473  0.18745253  0.\n",
      "   0.31738473  0.          0.        ]\n",
      " [ 0.54645401  0.          0.          0.          0.          0.          0.\n",
      "   0.54645401  0.54645401  0.          0.32274454  0.          0.          0.\n",
      "   0.        ]\n",
      " [ 0.          0.35517252  0.          0.          0.          0.27011786\n",
      "   0.          0.          0.          0.          0.20977061  0.35517252\n",
      "   0.          0.35517252  0.71034504]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "transformer = TfidfTransformer()\n",
    "tfidf  = transformer.fit_transform(X)\n",
    "weight = tfidf.toarray()    \n",
    "print(weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x15 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 18 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.          0.06049928  0.10452288]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_similarity(tfidf[0], tfidf)\n",
    "#cosine_similarity(tfidf, tfidf)\n",
    "cosine_similarities = cosine_similarity(tfidf[0], tfidf).flatten()\n",
    "print(cosine_similarities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【更新】柯P：洪智坤洩漏公文案還沒看到公文　今處理\n",
      "人事處議處洪智坤　柯P：不清楚議處結果\n",
      "留洪智坤 柯：殘障求職不易\n"
     ]
    }
   ],
   "source": [
    "related_docs_indices = cosine_similarities.argsort()[::-1]\n",
    "for index in related_docs_indices:\n",
    "    print(ary[index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "a = [2,3,1,4,5]\n",
    "a.sort()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 1 0 2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = [2,3,1,4,5]\n",
    "b = np.array(a).argsort()[-2::-1]\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 找出最類似文章"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "news = pandas.read_excel('news.xlsx')\n",
    "#news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus = []\n",
    "titles = []\n",
    "for article in news.iterrows():\n",
    "    titles.append(article[1].title)\n",
    "    corpus.append(' '.join(jieba.cut(article[1].content)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer() \n",
    "X = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "transformer = TfidfTransformer()\n",
    "tfidf  = transformer.fit_transform(X)\n",
    "weight = tfidf.toarray()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【央廣RTI】選前拋震撼彈 夢工廠巨頭批...(46) 1.0\n",
      "【央廣RTI】FBI維持不起訴 川普舊調...(985) 0.305619577147\n",
      "【法廣RFI】 FBI: 電郵門新調查維...(1095) 0.302779689415\n",
      "希拉蕊電郵案解套　川普怒批FBI(2569) 0.274209134022\n",
      "【央廣RTI】FBI維持不起訴希拉蕊 墨...(930) 0.264437276947\n",
      "FBI仍建議不起訴希拉蕊　但傷害已造成(5197) 0.25274064567\n",
      "【大選片】再查電郵門結果出爐　FBI維持...(56967) 0.236939059422\n",
      "​美國大選前最新民調　希拉蕊仍領先川普(2285) 0.181472150818\n",
      "【央廣RTI】若希拉蕊當選 如何稱呼柯林...(56) 0.178684438567\n",
      "【法廣RFI】川普“竟跑”五個州 希拉蕊...(2470) 0.155995348849\n",
      "【央廣RTI】大選衝刺 NBA球星詹皇為...(832) 0.140339552229\n",
      "【美國大選專題】美國史上首位第一先生？(2707) 0.122368752005\n",
      "【站台片】詹皇忙裡偷閒　幫希拉蕊拉票(3529) 0.0938148451754\n",
      "觀望美國大選　台幣匯價早盤陷入整理(1086) 0.0742889451802\n",
      "【民報】有影沒？美頂尖史學家預測川普20...(3051) 0.0741746574282\n",
      "美國重燃「希」望　避險資產日圓、黃金回跌(2298) 0.0730760173042\n",
      "【央廣RTI】尼加拉瓜總統大選 奧蒂嘉夫...(391) 0.0686146854748\n",
      "美總統誰當選？　彭勝竹引美媒體說「用槍自...(2788) 0.0617650408965\n",
      "電郵門大轉折　台股開高重返9100點(1892) 0.0572423445437\n",
      "【有片】權值股領軍　台股大漲121點收復...(929) 0.0536958838488\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "cosine_similarities = cosine_similarity(tfidf[8], tfidf).flatten()\n",
    "related_docs_indices = cosine_similarities.argsort()[-2::-1]\n",
    "\n",
    "for idx in related_docs_indices:\n",
    "    if cosine_similarities[idx] > 0.05:\n",
    "        print(titles[idx], cosine_similarities[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立找尋最相關文章函式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "def getSimiliarArticle(articleid):\n",
    "    print('[查詢文章]:{}'.format(titles[articleid]))\n",
    "    cosine_similarities = cosine_similarity(tfidf[articleid], tfidf).flatten()\n",
    "    related_docs_indices = cosine_similarities.argsort()[-2::-1]\n",
    "\n",
    "    for idx in related_docs_indices:\n",
    "        if cosine_similarities[idx] > 0.05:\n",
    "            print('[相關文章]:{} {}'.format(titles[idx], cosine_similarities[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[查詢文章]:經營職棒比想像複雜　年輕球員將多加薪(3054)\n",
      "[相關文章]:富邦正式成軍　吉祥物不是老鷹(6526) 0.292471981520166\n",
      "[相關文章]:補強考慮他隊球員　前興農牛成員將加入(1527) 0.16033741004420532\n",
      "[相關文章]:富邦勇士吉祥物「籃球保護者」亮相　雄赳赳...(916) 0.13429499363157807\n",
      "[相關文章]:世界大賽2球星與建仔隊友　有可能被交易(12768) 0.064655878392021\n",
      "[相關文章]:今天立冬　鄭明典：明天降溫有感(2894) 0.06445545755372571\n",
      "[相關文章]:【有玄機】今天立冬　達人教你這樣做(5399) 0.06237794539515276\n",
      "[相關文章]:【天氣片】今立冬高溫飆30℃　周三起北台...(4128) 0.057752093572872754\n",
      "[相關文章]:評兩岸關係　彭勝竹：外弛內張且持續壓迫我...(760) 0.051283100064320734\n"
     ]
    }
   ],
   "source": [
    "getSimiliarArticle(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from xml.dom   import minidom\n",
    "from xml.etree import ElementTree\n",
    "import jieba.analyse\n",
    "\n",
    "with open('1435449602.xml', 'r', encoding='utf-8') as f:\n",
    "    events = ElementTree.fromstring(f.read())\n",
    "\n",
    "corpus = []\n",
    "ary    = []\n",
    "for elem in events.findall('./channel/item'):\n",
    "    title       = elem.find('title').text\n",
    "    description = elem.find('description').text\n",
    "    word_list = []\n",
    "    \n",
    "    ary.append(title)\n",
    "    for word in jieba.cut(description):\n",
    "        if re.match('[\\u4e00-\\u9fa5]+', word):\n",
    "            word_list.append(word)\n",
    "    corpus.append(' '.join(word_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer() \n",
    "X = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "transformer = TfidfTransformer()\n",
    "tfidf  = transformer.fit_transform(X)\n",
    "weight = tfidf.toarray()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word = vectorizer.get_feature_names() \n",
    "#print(' '.join(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(147, 12248)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "n_cosine_similarities = cosine_similarity(tfidf, tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.10502505,  0.00455773, ...,  0.11666613,\n",
       "         0.01667092,  0.01242793],\n",
       "       [ 0.10502505,  1.        ,  0.0153138 , ...,  0.10593473,\n",
       "         0.01586742,  0.00795129],\n",
       "       [ 0.00455773,  0.0153138 ,  1.        , ...,  0.00857993,\n",
       "         0.        ,  0.        ],\n",
       "       ..., \n",
       "       [ 0.11666613,  0.10593473,  0.00857993, ...,  1.        ,\n",
       "         0.01689612,  0.01757607],\n",
       "       [ 0.01667092,  0.01586742,  0.        , ...,  0.01689612,\n",
       "         1.        ,  0.21282872],\n",
       "       [ 0.01242793,  0.00795129,  0.        , ...,  0.01757607,\n",
       "         0.21282872,  1.        ]])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_cosine_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cluster\n",
    "c = cluster.KMeans(n_clusters=4)\n",
    "k_data = c.fit_predict(weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "江蕙得「特別貢獻獎」 感恩金曲肯定她\n",
      "羅志祥哭了 蔡依林讚表現很好\n",
      "蔡依林淚奪金曲 錦榮傳訊恭喜\n",
      "陳奕迅、張惠妹稱王封后  蔡依林抱回最大獎\n",
      "陳奕迅、莫文蔚伴侶均不知阿娜答金曲獲獎\n",
      "金曲26／陳奕迅二度擊敗張學友　濕身奪歌王\n",
      "金曲26／蔡依林擒３獎大勝　淚崩再挺婚姻平權\n",
      "金曲26／張惠妹奪歌后卻失落　要世界感受彩虹力量\n",
      "金曲26／蔡依林淚奪最佳專輯＋完整得獎名單\n",
      "僅次Jolin！徐佳瑩入圍6獎全槓被封遺珠\n",
      "金曲最風光！蔡依林紅毯全勝又獲3獎成大贏家\n",
      "張惠妹3度封后  想破江蕙紀錄\n",
      "金曲26／陳奕迅稱王謝台灣　張惠妹封后秒噴淚\n",
      "蔡依林呸大贏家  金曲最佳專輯獎\n",
      "陳奕迅二度打敗歌神  金曲歌王好嗨\n",
      "金曲獎完整得獎名單！阿妹封后 陳奕迅稱王\n",
      "第26屆金曲獎 陳奕迅奪歌王、阿妹封歌后\n",
      "金曲最佳國語專輯：呸\n",
      "《金曲26》2015金曲獎得獎名單 線上直播懶人包\n"
     ]
    }
   ],
   "source": [
    "clusters = np.where(k_data == 3)[0].tolist()\n",
    "for idx in clusters:\n",
    "    print(ary[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 讀取新聞資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "with sqlite3.connect('news.sqlite') as db:\n",
    "    cur = db.cursor()\n",
    "    cur.execute('select title, summary, category from news_entry')\n",
    "    allNews = cur.fetchall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corpus  = []\n",
    "ary     = []\n",
    "tags    = []\n",
    "for rec in allNews:\n",
    "    if (rec[2] == '娛樂') or (rec[2] == '社會'):\n",
    "        ary.append(rec[0])\n",
    "        corpus.append(' '.join(jieba.cut(rec[1])))\n",
    "        tags.append(rec[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer() \n",
    "X = vectorizer.fit_transform(corpus)\n",
    "word = vectorizer.get_feature_names() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "train_data, test_data, train_tag, test_tag = train_test_split(X, tags, test_size=0.50, random_state=42)\n",
    "train_title2, test_title2, train_tag2, test_tag2= train_test_split(ary, tags, test_size=0.50, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(346, 17234)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(173, 17234)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(173, 17234)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB(alpha=0.01)\n",
    "clf.fit(train_data,train_tag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = clf.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 56,   1],\n",
       "       [  2, 114]])"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "#test_tag\n",
    "#pred\n",
    "confusion_matrix(test_tag, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98265895953757221"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test_tag, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 ('社會', '娛樂') 曾自爆和死亡擦身　李敖現身北檢裝神祕\n",
      "60 ('娛樂', '社會') 直擊黃安新竹喝咖啡　網友：早知就點熱咖啡\n",
      "172 ('社會', '娛樂') 【公庫】帶孩子回安全的家 賈靜雯擔任受暴...\n"
     ]
    }
   ],
   "source": [
    "for idx, w in enumerate(zip(test_tag, pred)):\n",
    "    if w[0] != w[1]:\n",
    "        print(idx, w, test_title2[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
